{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa670166-ec60-46dd-83f8-3f448263b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07eab68-3275-4e3c-baa4-72f36c23516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from custom_utils.custom_utils import *\n",
    "from custom_utils.custompnn_utils import *\n",
    "from custom_utils.dataloader_mod import *\n",
    "from custom_utils.tent_mod import *\n",
    "from custom_utils.dataloader_TTA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fb0c47-c7ff-4ae9-a20f-ec18073ff645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU availability :  True\n"
     ]
    }
   ],
   "source": [
    "print('GPU availability : ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:4')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395676a1-e10a-4eb9-a7c4-dbd064c2d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2025\n",
    "\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0004f9-8538-45af-8cdc-78ee3fd73490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca14f052-1e7b-4558-baae-416d41599cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ = [0.7682, 0.4299, 0.4733]\n",
    "std_ = [0.2421, 0.2967, 0.2483]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((64,64)),\n",
    "                transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=mean_,\n",
    "                              std=std_)\n",
    "            ])\n",
    "\n",
    "dataset = DigitData('.', size=64, transform=transform)\n",
    "#dataset, _ = random_split(dataset, [0.1, 0.9])\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223a9f2-187f-445d-8702-5c1eb2fa39d4",
   "metadata": {},
   "source": [
    "## Tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a91d4f68-b41e-4d47-8e7b-ad6694e04846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAdapter(nn.Module):\n",
    "    def __init__(self, dim=512, h_dim=64):\n",
    "        super().__init__()\n",
    "        self.down = nn.Linear(dim, h_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.up = nn.Linear(h_dim, dim)\n",
    "        \n",
    "        nn.init.zeros_(self.up.weight)\n",
    "        nn.init.zeros_(self.up.bias)\n",
    "    def forward(self, x):\n",
    "        #print(self.up(self.relu(self.down(x))).sum())\n",
    "        return x + self.up(self.relu(self.down(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e8c5da6-e3d3-4393-bb74-feb4caaef5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_entropy_(output, multi = True):\n",
    "    \"\"\"Entropy of softmax distribution from logits.\"\"\"\n",
    "    temprature = 1\n",
    "    output = output/temprature\n",
    "    if multi:\n",
    "        p = output.softmax(dim = -1).mean(dim=0).clamp(min=1e-12)\n",
    "    else:\n",
    "        p = output.softmax(dim = -1).clamp(min=1e-12)\n",
    "    # p: bsz, 10 -> output: bsz\n",
    "    entropy = -(p * torch.log(p)).sum(1)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81724046-d028-4a2e-a193-6a9ed3d7b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone=None, n_way=10, normalize=True, proto=None, adapt=False):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        if backbone:\n",
    "            self.backbone = backbone\n",
    "        else:\n",
    "            resnet_pt = models.resnet18(weights=\"ResNet18_Weights.IMAGENET1K_V1\")\n",
    "            resnet_pt.fc = nn.Flatten()\n",
    "            self.backbone = resnet_pt\n",
    "        self.n_way = n_way\n",
    "        self.normalize = normalize\n",
    "        self.proto = proto\n",
    "        self.adapt = adapt\n",
    "        if self.adapt:\n",
    "            self.adapter = ResidualAdapter()\n",
    "        \n",
    "    def forward(self, images, dist=None):\n",
    "        proto = self.proto\n",
    "        if self.adapt:\n",
    "            proto = self.adapter(self.proto)\n",
    "        \n",
    "        z = F.normalize(self.backbone.forward(images))\n",
    "        if dist == None:\n",
    "            dists = self.euclidean_distance(z, proto)  # [Q, N]\n",
    "        else:\n",
    "            dists = dist(x, y)\n",
    "        return -dists\n",
    "    \n",
    "\n",
    "    def euclidean_distance(self, x, y):\n",
    "        n = x.shape[0]  # Q\n",
    "        m = y.shape[0]  # N\n",
    "        d = x.shape[1]\n",
    "        assert d == y.shape[1]\n",
    "\n",
    "        # x -> [Q, 1, D], y -> [1, N, D]\n",
    "        x = x.unsqueeze(1).expand(n, m, d)\n",
    "        y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "        return torch.pow(x - y, 2).sum(2)\n",
    "    \n",
    "    def GetProto(self):\n",
    "        return self.proto\n",
    "    \n",
    "    def update_proto(self, images, pred, momentum = 0.9):\n",
    "        z = F.normalize(self.backbone.forward(images)) # bsz, emb_dim\n",
    "        count_list = torch.tensor([(pred==label).sum() for label in range(10)]).to(self.proto.device) # list of len 10\n",
    "        z_proto = torch.cat([\n",
    "            nn.functional.normalize(z[torch.nonzero(pred == label)].mean(0)) if count_list[label]!=0 else torch.zeros(1,z.shape[-1]).to(self.proto.device) for label in range(self.n_way)\n",
    "        ]).to(self.proto.device)\n",
    "        momentum_ = count_list*(momentum/count_list.sum()).to(self.proto.device) # list of len 10\n",
    "        proto_new = self.proto*(1-momentum_).unsqueeze(1) + z_proto*momentum_.unsqueeze(1)\n",
    "        self.proto = F.normalize(proto_new)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af7854e4-b4da-4b6f-9239-66461bae7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tent_PNN(nn.Module):\n",
    "    \"\"\"Tent adapts a model by entropy minimization during testing.\n",
    "\n",
    "    Once tented, a model adapts itself by updating on every forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, optimizer, steps=1, episodic=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.steps = steps\n",
    "        assert steps > 0, \"tent requires >= 1 step(s) to forward and update\"\n",
    "        self.episodic = episodic\n",
    "\n",
    "        # note: if the model is never reset, like for continual adaptation,\n",
    "        # then skipping the state copy would save memory\n",
    "        self.model_state, self.optimizer_state = \\\n",
    "            copy_model_and_optimizer(self.model, self.optimizer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.episodic:\n",
    "            self.reset()\n",
    "\n",
    "        for _ in range(self.steps):\n",
    "            outputs = forward_and_adapt_(x, self.model, self.optimizer)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def reset(self):\n",
    "        if self.model_state is None or self.optimizer_state is None:\n",
    "            raise Exception(\"cannot reset without saved model/optimizer state\")\n",
    "        load_model_and_optimizer(self.model, self.optimizer,\n",
    "                                 self.model_state, self.optimizer_state)\n",
    "        \n",
    "def copy_model_and_optimizer(model, optimizer):\n",
    "    \"\"\"Copy the model and optimizer states for resetting after adaptation.\"\"\"\n",
    "    model_state = deepcopy(model.state_dict())\n",
    "    optimizer_state = deepcopy(optimizer.state_dict())\n",
    "    return model_state, optimizer_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9b97397-1bac-44e2-80cf-21a8f2e44b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_adapt_(x, model, optimizer):\n",
    "    \"\"\"Forward and adapt model on batch of data.\n",
    "\n",
    "    Measure entropy of the model prediction, take gradients, and update params.\n",
    "    \"\"\"\n",
    "    # forward\n",
    "    outputs = model(x)\n",
    "    # adapt\n",
    "    loss = softmax_entropy(outputs).mean(0)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # update prototype\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x)\n",
    "        log_p_y = F.log_softmax(outputs, dim = 1)\n",
    "        tmp_pred = torch.max(log_p_y.data, axis = 1)[1]\n",
    "        model.update_proto(x, tmp_pred)\n",
    "    # return outputs\n",
    "    return model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "44d281a9-13f2-4230-9f18-a7ac8248e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tent_PNN2(nn.Module):\n",
    "    \"\"\"Tent adapts a model by entropy minimization during testing.\n",
    "\n",
    "    Once tented, a model adapts itself by updating on every forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, optimizer, optimizer2, steps=1, episodic=False, adapt_step=3):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.optimizer2 = optimizer\n",
    "        self.steps = steps\n",
    "        assert steps > 0, \"tent requires >= 1 step(s) to forward and update\"\n",
    "        self.episodic = episodic\n",
    "        self.adapt_step = adapt_step\n",
    "\n",
    "        # note: if the model is never reset, like for continual adaptation,\n",
    "        # then skipping the state copy would save memory\n",
    "        self.model_state, self.optimizer_state = \\\n",
    "            copy_model_and_optimizer(self.model, self.optimizer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.episodic:\n",
    "            self.reset()\n",
    "\n",
    "        for idx in range(self.steps):\n",
    "            outputs = forward_and_adapt_2(x, self.model, self.optimizer, self.optimizer2, self.adapt_step, idx)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def reset(self):\n",
    "        if self.model_state is None or self.optimizer_state is None:\n",
    "            raise Exception(\"cannot reset without saved model/optimizer state\")\n",
    "        load_model_and_optimizer(self.model, self.optimizer,\n",
    "                                 self.model_state, self.optimizer_state)\n",
    "        \n",
    "        \n",
    "def forward_and_adapt_2(x, model, optimizer, optimizer2, adapt_step, idx):\n",
    "    \"\"\"Forward and adapt model on batch of data.\n",
    "\n",
    "    Measure entropy of the model prediction, take gradients, and update params.\n",
    "    \"\"\"\n",
    "    # forward\n",
    "    # adapt\n",
    "    if idx == 0:\n",
    "        for _ in range(adapt_step):\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = softmax_entropy(outputs).mean(0)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x)\n",
    "    z = F.normalize(model.backbone.forward(x))\n",
    "    \n",
    "    loss = softmax_entropy(outputs).mean(0)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if idx == 0:\n",
    "        # update prototype\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "            log_p_y = F.log_softmax(outputs, dim = 1)\n",
    "            tmp_pred = torch.max(log_p_y.data, axis = 1)[1]\n",
    "            #model.update_proto(x, tmp_pred)\n",
    "        # return outputs\n",
    "    return model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "32ed73ba-d0be-4c95-9055-52f8a820dd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 512])\n"
     ]
    }
   ],
   "source": [
    "for image, y in data_loader:\n",
    "    print(image.shape)\n",
    "    image = image.to(device)\n",
    "    output = model.backbone.forward(image)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "1f031c8d-41f8-46d8-9a71-ce43c7320601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_utils.tent_mod as tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "0a9d72a8-e456-452c-9613-22a3811ffcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['adapter.down.weight', 'adapter.down.bias', 'adapter.up.weight', 'adapter.up.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PrototypicalNetworks(proto=torch.load('model/20250428_proto.pt'), adapt=True)\n",
    "\n",
    "model.load_state_dict(torch.load('model/20250428_protonet.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "ce57034c-d412-44d4-9a73-69fe5168631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_configure_model(model)\n",
    "params, param_names = custom_collect_params(model)\n",
    "optimizer = optim.Adam(params, lr=2.5e-4)\n",
    "optimizer2 = optim.Adam(model.adapter.parameters(), lr=1e-3)\n",
    "tented_model = Tent_PNN2(model, optimizer, optimizer2, steps=1, episodic=False, adapt_step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "e22ddb2c-8d88-4bef-855c-d3d137b00fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in tented_model.named_parameters():\n",
    "#     print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "291fa25c-d9da-49d0-9f58-f9b2a30c628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tented_model = tented_model.to(device)\n",
    "tented_model.model.proto = tented_model.model.proto.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "25562a08-60fc-43dc-939d-f7ebd33d050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 49.59%\n",
      "F1 : 48.43%\n"
     ]
    }
   ],
   "source": [
    "preds, targets = test_tent_PNN(data_loader, tented_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "bd1ab415-a09f-4ca3-a160-4575e14747b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 53.59%\n",
      "F1 : 52.83%\n",
      "Acc: 59.70%\n",
      "F1 : 59.41%\n",
      "Acc: 63.52%\n",
      "F1 : 63.39%\n",
      "Acc: 66.38%\n",
      "F1 : 66.20%\n",
      "Acc: 66.79%\n",
      "F1 : 66.76%\n",
      "Acc: 66.70%\n",
      "F1 : 66.83%\n",
      "Acc: 68.70%\n",
      "F1 : 68.69%\n",
      "Acc: 69.62%\n",
      "F1 : 69.60%\n",
      "Acc: 70.16%\n",
      "F1 : 70.19%\n",
      "Acc: 71.23%\n",
      "F1 : 71.37%\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    preds, targets = test_tent_PNN(data_loader, tented_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "25795e1e-7f38-4f61-8e6c-58b06a0f87c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.010000000000005, 26.22230958554185, 32.674, 25.963522565322297)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + adapter, 5 steps, adapt_step=10, lr=2.5e-4, 1e-3\n",
    "ac = np.array([56.62, 50.49, 55.94, 1, 1])\n",
    "f1 = np.array([56.33, 49.63, 55.41, 1, 1])\n",
    "\n",
    "ac.mean(), ac.std(), f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0e1d8b18-a973-405a-8d08-7625694fd30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.35, 1.8541628838912738, 54.838, 2.014223423555589)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + adapter, 1 steps, adapt_step=10, lr=2.5e-4, 1e-3\n",
    "ac = np.array([53.73, 55.91, 53.43, 55.09, 58.59])\n",
    "f1 = np.array([53.17, 55.84, 52.38, 54.73, 58.07])\n",
    "\n",
    "ac.mean(), ac.std(), f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b31b3b32-cfa5-4f26-8dcb-4580ca93c963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53.388, 2.353128980740325, 52.924, 2.567166531411626)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + adapter, 5 steps, adapt_step=3\n",
    "ac = np.array([51.20, 54.88, 54.22, 50.16, 56.48])\n",
    "f1 = np.array([50.47, 54.74, 54.00, 49.36, 56.05])\n",
    "\n",
    "ac.mean(), ac.std(), f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0ab18dd3-05b8-4cdb-b5a2-fe80a560d750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.05, 0.7436396977031278, 48.97, 0.7750354830586804)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + adapter, 1 steps, adapt_step=1\n",
    "ac = np.array([48.61, 50.55, 50.39, 50.08, 50.62])\n",
    "f1 = np.array([47.51, 49.59, 49.26, 48.89, 49.60])\n",
    "\n",
    "ac.mean(), ac.std(), f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "99578de7-1800-4ff1-84a0-67c7e9abb74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51.79, 1.793309789188694, 50.774, 1.837200043544523)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# + adapter, 1 steps, adapt_step=3\n",
    "ac = np.array([49.64, 50.27, 52.95, 54.57, 51.52])\n",
    "f1 = np.array([48.57, 49.19, 52.21, 53.48, 50.42])\n",
    "\n",
    "ac.mean(), ac.std(), f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede29f95-a377-46bf-b15b-b7dd23b463cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base, 5 steps\n",
    "ac = np.array([51.04, 50.19, 50.66, 52.23, 51.82])\n",
    "f1 = np.array([50.07, 49.07, 49.66, 51.31, 50.86])\n",
    "\n",
    "ac.mean(), ac.std(), f1.mean(), f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b19a5-4671-4fa2-a8d6-4b39b0afd1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e21271-1df5-4bac-8dd6-7ec9c11c82cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb39c59b-6ab1-4bb5-a677-58aa562bcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tent_PNN(data_loader, tented_model):\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = tented_model(data) # -distance: bsz, 10\n",
    "        pred = torch.max(output.data, axis = 1)[1]\n",
    "\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        targets.extend(target.cpu().numpy())\n",
    "\n",
    "    print('Acc: {:.2f}%'.format(100*accuracy_score(targets, preds)))\n",
    "    print('F1 : {:.2f}%'.format(100*f1_score(targets, preds, average='macro')))\n",
    "    \n",
    "    return preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8a332bcd-57e9-4a84-94c0-7c596d1b35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collect_params(model):\n",
    "    params = []\n",
    "    names = []\n",
    "    for nm, m in model.named_modules():\n",
    "        # BatchNorm2d 파라미터 (weight, bias)\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            for np, p in m.named_parameters(recurse=False):\n",
    "                if np in ['weight', 'bias']:\n",
    "                    params.append(p)\n",
    "                    names.append(f\"{nm}.{np}\")\n",
    "        # Adapter 파라미터 추가 (ResidualAdapter 등)\n",
    "        # - ResidualAdapter를 정확히 구분하려면 이름 또는 클래스 기반\n",
    "        # if 'adapter' in nm or isinstance(m, ResidualAdapter):\n",
    "        #     for np, p in m.named_parameters(recurse=False):\n",
    "        #         params.append(p)\n",
    "        #         names.append(f\"{nm}.{np}\")\n",
    "    return params, names\n",
    "\n",
    "\n",
    "def custom_configure_model(model):\n",
    "    # train mode, because tent optimizes the model to minimize entropy\n",
    "    model.train()\n",
    "    # disable grad, to (re-)enable only what tent updates\n",
    "    model.requires_grad_(False)\n",
    "    # configure norm for tent updates: enable grad + force batch statisics\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.requires_grad_(True)\n",
    "            # force use of batch stats in train and eval modes\n",
    "            m.track_running_stats = False\n",
    "            m.running_mean = None\n",
    "            m.running_var = None\n",
    "            \n",
    "        if isinstance(m, ResidualAdapter):\n",
    "            m.requires_grad_(True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e851b7f-d52b-4853-a517-7f8964cb26a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prml",
   "language": "python",
   "name": "prml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
